{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b185d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (400000, 8)\n",
      "\n",
      "Label Counts:\n",
      " label\n",
      "0    200000\n",
      "1    200000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature Summary:\n",
      "         time_to_submit                                         user_agent  \\\n",
      "count    400000.000000                                             400000   \n",
      "unique             NaN                                                  8   \n",
      "top                NaN  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...   \n",
      "freq               NaN                                              70339   \n",
      "mean          3.532361                                                NaN   \n",
      "std           3.872805                                                NaN   \n",
      "min           0.010000                                                NaN   \n",
      "25%           0.309767                                                NaN   \n",
      "50%           0.838234                                                NaN   \n",
      "75%           6.761922                                                NaN   \n",
      "max          12.683748                                                NaN   \n",
      "\n",
      "           login_hour  client_ip  password_length  \\\n",
      "count   400000.000000     400000    400000.000000   \n",
      "unique            NaN          8              NaN   \n",
      "top               NaN  45.77.1.3              NaN   \n",
      "freq              NaN      50680              NaN   \n",
      "mean        11.508458        NaN        10.500298   \n",
      "std          6.925539        NaN         2.873088   \n",
      "min          0.000000        NaN         6.000000   \n",
      "25%          6.000000        NaN         8.000000   \n",
      "50%         12.000000        NaN        11.000000   \n",
      "75%         18.000000        NaN        13.000000   \n",
      "max         23.000000        NaN        15.000000   \n",
      "\n",
      "        failed_login_count_last_10min  is_username_email          label  \n",
      "count                   400000.000000      400000.000000  400000.000000  \n",
      "unique                            NaN                NaN            NaN  \n",
      "top                               NaN                NaN            NaN  \n",
      "freq                              NaN                NaN            NaN  \n",
      "mean                         1.949288           0.499980       0.500000  \n",
      "std                          2.087245           0.500001       0.500001  \n",
      "min                          0.000000           0.000000       0.000000  \n",
      "25%                          0.000000           0.000000       0.000000  \n",
      "50%                          1.000000           0.000000       0.500000  \n",
      "75%                          3.000000           1.000000       1.000000  \n",
      "max                         15.000000           1.000000       1.000000  \n",
      "\n",
      "Missing Values:\n",
      " time_to_submit                   0\n",
      "user_agent                       0\n",
      "login_hour                       0\n",
      "client_ip                        0\n",
      "password_length                  0\n",
      "failed_login_count_last_10min    0\n",
      "is_username_email                0\n",
      "label                            0\n",
      "dtype: int64\n",
      "\n",
      "✅ Saved to balanced_login_data.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script to generate a balanced synthetic dataset for the login-behavior model.\n",
    "Creates ~400,000 rows (200,000 benign, 200,000 attack) with 7 behavioral features\n",
    "and a Label column (0=Benign, 1=Attack). Saves to balanced_login_data.csv.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "N_PER_CLASS = 200_000  # 200k benign + 200k attack\n",
    "OUTPUT_PATH = \"balanced_login_data.csv\"\n",
    "\n",
    "# Feature distributions\n",
    "USER_AGENTS = [\n",
    "    # Human-like\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.5 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:118.0) Gecko/20100101 Firefox/118.0\",\n",
    "    # Bot-like\n",
    "    \"curl/8.5.0\",\n",
    "    \"python-requests/2.28.1\",\n",
    "    \"go-http-client/1.1\",\n",
    "    \"Wget/1.20.3\",\n",
    "    \"Scrapy/2.7.0\"\n",
    "]\n",
    "IP_POOL = [\n",
    "    \"203.0.113.1\", \"203.0.113.2\", \"45.77.1.3\", \"51.15.39.9\", \"192.0.2.1\",\n",
    "    # Additional IPs for diversity\n",
    "    \"192.168.1.100\", \"10.0.0.50\", \"172.16.0.10\"\n",
    "]\n",
    "\n",
    "# Generate data\n",
    "data = {\n",
    "    \"time_to_submit\": np.concatenate([\n",
    "        # Benign: Human-like, 1.5–12s with slight Gaussian noise\n",
    "        np.random.uniform(1.5, 12, N_PER_CLASS) + np.random.normal(0, 0.2, N_PER_CLASS),\n",
    "        # Attack: Bot-like, 0.02–0.6s\n",
    "        np.random.uniform(0.02, 0.6, N_PER_CLASS) + np.random.normal(0, 0.05, N_PER_CLASS)\n",
    "    ]),\n",
    "    \"user_agent\": np.concatenate([\n",
    "        # Benign: Mostly human-like browsers (80%), some bot-like (20%)\n",
    "        np.random.choice(USER_AGENTS, N_PER_CLASS, p=[0.3, 0.3, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]),\n",
    "        # Attack: Mostly bot-like (80%), some human-like (20%)\n",
    "        np.random.choice(USER_AGENTS, N_PER_CLASS, p=[0.05, 0.05, 0.1, 0.3, 0.2, 0.2, 0.05, 0.05])\n",
    "    ]),\n",
    "    \"login_hour\": np.random.choice(range(24), 2 * N_PER_CLASS),  # Uniform for both\n",
    "    \"client_ip\": np.random.choice(IP_POOL, 2 * N_PER_CLASS),  # Uniform for both\n",
    "    \"password_length\": np.random.choice(range(6, 16), 2 * N_PER_CLASS),  # Uniform 6–15\n",
    "    \"failed_login_count_last_10min\": np.concatenate([\n",
    "        # Benign: Low fails (Poisson mean 0.4)\n",
    "        np.random.poisson(0.4, N_PER_CLASS),\n",
    "        # Attack: High fails (Poisson mean 3.5)\n",
    "        np.random.poisson(3.5, N_PER_CLASS)\n",
    "    ]),\n",
    "    \"is_username_email\": np.random.choice([0, 1], 2 * N_PER_CLASS),  # Uniform for both\n",
    "    \"label\": np.concatenate([\n",
    "        np.zeros(N_PER_CLASS, dtype=int),  # Benign\n",
    "        np.ones(N_PER_CLASS, dtype=int)   # Attack\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Clip time_to_submit to ensure no negative values\n",
    "df[\"time_to_submit\"] = df[\"time_to_submit\"].clip(lower=0.01)\n",
    "\n",
    "# Shuffle rows\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Validate\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nLabel Counts:\\n\", df[\"label\"].value_counts())\n",
    "print(\"\\nFeature Summary:\\n\", df.describe(include=\"all\"))\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"\\n✅ Saved to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd92872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Canada\\Subjects\\Semester -2\\AIDI-2005-02 CAPSTONE TERM ll\\Bot_detector\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-07-17 11:16:46,810] A new study created in memory with name: no-name-3bfd8343-d857-458f-b2c9-00548d2d89b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:16:49,712] Trial 0 finished with value: 0.9999999075 and parameters: {'learning_rate': 0.16755889233749574, 'num_leaves': 16, 'max_depth': 13, 'feature_fraction': 0.6972529424542786, 'bagging_fraction': 0.8018172797108292, 'bagging_freq': 4, 'min_data_in_leaf': 33, 'lambda_l1': 2.480643012181809, 'lambda_l2': 0.8682096696093994}. Best is trial 0 with value: 0.9999999075.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:16:54,237] Trial 1 finished with value: 0.999999905 and parameters: {'learning_rate': 0.08197881344662493, 'num_leaves': 40, 'max_depth': 7, 'feature_fraction': 0.6130251396579516, 'bagging_fraction': 0.5480146493991442, 'bagging_freq': 9, 'min_data_in_leaf': 89, 'lambda_l1': 0.16368394435161027, 'lambda_l2': 3.7726843362704776}. Best is trial 0 with value: 0.9999999075.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:16:58,022] Trial 2 finished with value: 0.99999990625 and parameters: {'learning_rate': 0.09066279879422103, 'num_leaves': 33, 'max_depth': 9, 'feature_fraction': 0.7262019355907539, 'bagging_fraction': 0.9708346908610962, 'bagging_freq': 3, 'min_data_in_leaf': 41, 'lambda_l1': 1.8037298305126714, 'lambda_l2': 3.392453239781948}. Best is trial 0 with value: 0.9999999075.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:16:58,393] Trial 3 finished with value: 0.9999999150000001 and parameters: {'learning_rate': 0.15263270352030653, 'num_leaves': 74, 'max_depth': 16, 'feature_fraction': 0.9018258180235299, 'bagging_fraction': 0.7175954528853183, 'bagging_freq': 2, 'min_data_in_leaf': 36, 'lambda_l1': 0.6563915189783964, 'lambda_l2': 1.8745909300963608}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:16:58,613] Trial 4 finished with value: 0.99999932625 and parameters: {'learning_rate': 0.04958469001009245, 'num_leaves': 128, 'max_depth': 4, 'feature_fraction': 0.8550814857721271, 'bagging_fraction': 0.7511257639832516, 'bagging_freq': 10, 'min_data_in_leaf': 44, 'lambda_l1': 1.1003250067417754, 'lambda_l2': 1.5423139993417834}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.999999\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:16:59,172] Trial 5 finished with value: 0.9999999099999999 and parameters: {'learning_rate': 0.10543667453741175, 'num_leaves': 121, 'max_depth': 9, 'feature_fraction': 0.5229651974833216, 'bagging_fraction': 0.5278479412700054, 'bagging_freq': 3, 'min_data_in_leaf': 89, 'lambda_l1': 0.8625513423973569, 'lambda_l2': 4.257377760581925}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:16:59,549] Trial 6 finished with value: 0.99999991375 and parameters: {'learning_rate': 0.14445712017752, 'num_leaves': 68, 'max_depth': 14, 'feature_fraction': 0.7360245903358317, 'bagging_fraction': 0.9301576806584424, 'bagging_freq': 9, 'min_data_in_leaf': 65, 'lambda_l1': 1.6559404564169662, 'lambda_l2': 1.723235100560558}. Best is trial 3 with value: 0.9999999150000001.\n",
      "[I 2025-07-17 11:16:59,711] Trial 7 finished with value: 0.99999932625 and parameters: {'learning_rate': 0.013224869005018763, 'num_leaves': 32, 'max_depth': 9, 'feature_fraction': 0.9801073871641772, 'bagging_fraction': 0.7268806751454806, 'bagging_freq': 7, 'min_data_in_leaf': 44, 'lambda_l1': 2.0356859978780046, 'lambda_l2': 2.4221343946487393}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:16:59,991] Trial 8 finished with value: 0.99999727 and parameters: {'learning_rate': 0.015430008066442754, 'num_leaves': 119, 'max_depth': 5, 'feature_fraction': 0.5797174463093162, 'bagging_fraction': 0.6006899416906202, 'bagging_freq': 3, 'min_data_in_leaf': 56, 'lambda_l1': 3.343341247877305, 'lambda_l2': 2.0586725429188006}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.999997\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:00,364] Trial 9 finished with value: 0.9999998925 and parameters: {'learning_rate': 0.07673401052256222, 'num_leaves': 91, 'max_depth': 4, 'feature_fraction': 0.9660461339951667, 'bagging_fraction': 0.9162145087953975, 'bagging_freq': 7, 'min_data_in_leaf': 57, 'lambda_l1': 0.3531576041708029, 'lambda_l2': 1.816671988543856}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:00,685] Trial 10 finished with value: 0.9999999075 and parameters: {'learning_rate': 0.19910771680586864, 'num_leaves': 75, 'max_depth': 16, 'feature_fraction': 0.861254511492092, 'bagging_fraction': 0.6611656136058659, 'bagging_freq': 1, 'min_data_in_leaf': 22, 'lambda_l1': 4.9585937701926, 'lambda_l2': 0.022150941694726534}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:01,038] Trial 11 finished with value: 0.99999991375 and parameters: {'learning_rate': 0.14023652777608098, 'num_leaves': 63, 'max_depth': 16, 'feature_fraction': 0.829205573063196, 'bagging_fraction': 0.846885641478154, 'bagging_freq': 6, 'min_data_in_leaf': 72, 'lambda_l1': 1.357168581650706, 'lambda_l2': 3.0023235135848862}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:01,390] Trial 12 finished with value: 0.99999990625 and parameters: {'learning_rate': 0.13723884418934845, 'num_leaves': 88, 'max_depth': 13, 'feature_fraction': 0.7780850803478094, 'bagging_fraction': 0.9030591244815062, 'bagging_freq': 1, 'min_data_in_leaf': 70, 'lambda_l1': 3.339668217471817, 'lambda_l2': 0.9238290171730787}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:01,781] Trial 13 finished with value: 0.9999999125000001 and parameters: {'learning_rate': 0.1410644279451928, 'num_leaves': 59, 'max_depth': 13, 'feature_fraction': 0.9052026842543608, 'bagging_fraction': 0.9990064703920745, 'bagging_freq': 8, 'min_data_in_leaf': 73, 'lambda_l1': 3.1294197511617083, 'lambda_l2': 1.3338311515412768}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:02,153] Trial 14 finished with value: 0.9999999075 and parameters: {'learning_rate': 0.176944914912552, 'num_leaves': 99, 'max_depth': 14, 'feature_fraction': 0.6570930475399449, 'bagging_fraction': 0.6820257944434062, 'bagging_freq': 5, 'min_data_in_leaf': 20, 'lambda_l1': 0.575905654921562, 'lambda_l2': 2.600223817578467}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:02,494] Trial 15 finished with value: 0.9999999125000001 and parameters: {'learning_rate': 0.11878502363819958, 'num_leaves': 55, 'max_depth': 11, 'feature_fraction': 0.7980412239546281, 'bagging_fraction': 0.8075661327847049, 'bagging_freq': 10, 'min_data_in_leaf': 59, 'lambda_l1': 1.4863760226868634, 'lambda_l2': 0.23936161739109707}. Best is trial 3 with value: 0.9999999150000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:02,933] Trial 16 finished with value: 0.9999999199999999 and parameters: {'learning_rate': 0.16296242250101053, 'num_leaves': 75, 'max_depth': 15, 'feature_fraction': 0.9199843192078083, 'bagging_fraction': 0.6271157784617101, 'bagging_freq': 5, 'min_data_in_leaf': 34, 'lambda_l1': 0.0009722459428442853, 'lambda_l2': 4.9156352459893995}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:03,350] Trial 17 finished with value: 0.99999991625 and parameters: {'learning_rate': 0.17113699148596795, 'num_leaves': 78, 'max_depth': 16, 'feature_fraction': 0.9173037319605992, 'bagging_fraction': 0.6192764826962867, 'bagging_freq': 2, 'min_data_in_leaf': 31, 'lambda_l1': 0.16309550287967747, 'lambda_l2': 4.912349372326578}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:03,779] Trial 18 finished with value: 0.9999999150000001 and parameters: {'learning_rate': 0.19892712226105108, 'num_leaves': 105, 'max_depth': 15, 'feature_fraction': 0.9064371285593952, 'bagging_fraction': 0.6117001416192767, 'bagging_freq': 5, 'min_data_in_leaf': 28, 'lambda_l1': 0.12660964238765882, 'lambda_l2': 4.775969748560408}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:04,091] Trial 19 finished with value: 0.99999991 and parameters: {'learning_rate': 0.17470887006116242, 'num_leaves': 83, 'max_depth': 11, 'feature_fraction': 0.992457888518927, 'bagging_fraction': 0.5971885342846321, 'bagging_freq': 4, 'min_data_in_leaf': 50, 'lambda_l1': 4.404039051987892, 'lambda_l2': 4.775629855516517}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:04,404] Trial 20 finished with value: 0.99999989125 and parameters: {'learning_rate': 0.12032987718826513, 'num_leaves': 47, 'max_depth': 11, 'feature_fraction': 0.9559282917518686, 'bagging_fraction': 0.50655646801848, 'bagging_freq': 2, 'min_data_in_leaf': 100, 'lambda_l1': 0.026686299884650606, 'lambda_l2': 4.015999400410618}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:04,770] Trial 21 finished with value: 0.9999999125 and parameters: {'learning_rate': 0.15950675312563262, 'num_leaves': 76, 'max_depth': 16, 'feature_fraction': 0.9100440991458832, 'bagging_fraction': 0.6749893852573191, 'bagging_freq': 2, 'min_data_in_leaf': 34, 'lambda_l1': 0.73192594892487, 'lambda_l2': 4.8937533564501505}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:05,102] Trial 22 finished with value: 0.99999990625 and parameters: {'learning_rate': 0.18493841530790703, 'num_leaves': 79, 'max_depth': 15, 'feature_fraction': 0.9164304704704612, 'bagging_fraction': 0.7184038064008764, 'bagging_freq': 2, 'min_data_in_leaf': 32, 'lambda_l1': 0.98895944673971, 'lambda_l2': 4.356933535314379}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:05,490] Trial 23 finished with value: 0.99999991875 and parameters: {'learning_rate': 0.15593815447923215, 'num_leaves': 101, 'max_depth': 15, 'feature_fraction': 0.8613776250214502, 'bagging_fraction': 0.6451788562292836, 'bagging_freq': 4, 'min_data_in_leaf': 39, 'lambda_l1': 0.5320485604380685, 'lambda_l2': 3.339353630922549}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:05,798] Trial 24 finished with value: 0.99999991 and parameters: {'learning_rate': 0.12530987674674804, 'num_leaves': 105, 'max_depth': 14, 'feature_fraction': 0.8353415872573752, 'bagging_fraction': 0.6303867084899133, 'bagging_freq': 4, 'min_data_in_leaf': 28, 'lambda_l1': 0.3915306523357245, 'lambda_l2': 3.311696238447647}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:06,144] Trial 25 finished with value: 0.9999999175000001 and parameters: {'learning_rate': 0.16023793957116927, 'num_leaves': 99, 'max_depth': 12, 'feature_fraction': 0.9440470880800094, 'bagging_fraction': 0.5689443451593756, 'bagging_freq': 6, 'min_data_in_leaf': 41, 'lambda_l1': 2.236507965874025, 'lambda_l2': 4.352664725552126}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:06,490] Trial 26 finished with value: 0.99999991625 and parameters: {'learning_rate': 0.15636699907341706, 'num_leaves': 96, 'max_depth': 12, 'feature_fraction': 0.8725270989345837, 'bagging_fraction': 0.5583009645067586, 'bagging_freq': 6, 'min_data_in_leaf': 48, 'lambda_l1': 2.520541126048929, 'lambda_l2': 3.647427238080839}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:06,799] Trial 27 finished with value: 0.99999991125 and parameters: {'learning_rate': 0.18581370536920896, 'num_leaves': 107, 'max_depth': 12, 'feature_fraction': 0.945422112972932, 'bagging_fraction': 0.5694345593500283, 'bagging_freq': 5, 'min_data_in_leaf': 51, 'lambda_l1': 3.949250025848094, 'lambda_l2': 4.405006327228879}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:07,023] Trial 28 finished with value: 0.99999932625 and parameters: {'learning_rate': 0.10459763514163894, 'num_leaves': 115, 'max_depth': 15, 'feature_fraction': 0.7954140887680629, 'bagging_fraction': 0.6472013778639256, 'bagging_freq': 7, 'min_data_in_leaf': 38, 'lambda_l1': 2.301260470527981, 'lambda_l2': 3.0059507146883675}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.999999\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-17 11:17:07,293] Trial 29 finished with value: 0.99999991 and parameters: {'learning_rate': 0.16398881909552104, 'num_leaves': 89, 'max_depth': 13, 'feature_fraction': 0.9971661139039512, 'bagging_fraction': 0.7768452992905411, 'bagging_freq': 6, 'min_data_in_leaf': 27, 'lambda_l1': 2.4126469095911363, 'lambda_l2': 4.028260777047949}. Best is trial 16 with value: 0.9999999199999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 1\n",
      "Best params: {'learning_rate': 0.16296242250101053, 'num_leaves': 75, 'max_depth': 15, 'feature_fraction': 0.9199843192078083, 'bagging_fraction': 0.6271157784617101, 'bagging_freq': 5, 'min_data_in_leaf': 34, 'lambda_l1': 0.0009722459428442853, 'lambda_l2': 4.9156352459893995}\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's auc: 1\n",
      "[40]\tvalid_0's auc: 1\n",
      "[60]\tvalid_0's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 1\n",
      "\n",
      "=== Results for threshold=0.5 ===\n",
      "AUC: 0.9999999199999999\n",
      "Confusion Matrix:\n",
      " [[19996     4]\n",
      " [    5 19995]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20000\n",
      "           1       1.00      1.00      1.00     20000\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "\n",
      "=== Results for threshold=0.4 ===\n",
      "AUC: 0.9999999199999999\n",
      "Confusion Matrix:\n",
      " [[19996     4]\n",
      " [    5 19995]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20000\n",
      "           1       1.00      1.00      1.00     20000\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "\n",
      "=== Results for threshold=0.3 ===\n",
      "AUC: 0.9999999199999999\n",
      "Confusion Matrix:\n",
      " [[19995     5]\n",
      " [    1 19999]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20000\n",
      "           1       1.00      1.00      1.00     20000\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                          Feature     Importance\n",
      "0                 time_to_submit  706153.471928\n",
      "5  failed_login_count_last_10min  299901.445651\n",
      "1                     user_agent   34540.979741\n",
      "2                     login_hour       6.856012\n",
      "3                      client_ip       0.000000\n",
      "4                password_length       0.000000\n",
      "6              is_username_email       0.000000\n",
      "\n",
      "✅ Saved model to app/models/login_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script to train a LightGBM model on balanced_login_data.csv for login-behavior classification.\n",
    "Encodes categorical features, splits data (90% train, 10% validation), tunes hyperparameters\n",
    "with Optuna, and saves the model as app/models/login_classifier.pkl.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import optuna\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"balanced_login_data.csv\"\n",
    "MODEL_PATH = \"app/models/login_classifier.pkl\"\n",
    "VALIDATION_SIZE = 0.1\n",
    "N_TRIALS = 30  # Number of Optuna trials for hyperparameter tuning\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 1. Load and preprocess data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Encode categorical features\n",
    "le_user_agent = LabelEncoder()\n",
    "le_client_ip = LabelEncoder()\n",
    "df[\"user_agent\"] = le_user_agent.fit_transform(df[\"user_agent\"])\n",
    "df[\"client_ip\"] = le_client_ip.fit_transform(df[\"client_ip\"])\n",
    "\n",
    "# Features and labels\n",
    "feature_cols = [\n",
    "    \"time_to_submit\",\n",
    "    \"user_agent\",\n",
    "    \"login_hour\",\n",
    "    \"client_ip\",\n",
    "    \"password_length\",\n",
    "    \"failed_login_count_last_10min\",\n",
    "    \"is_username_email\",\n",
    "]\n",
    "X = df[feature_cols]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Split data (90% train, 10% validation, stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=VALIDATION_SIZE, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# 2. Define Optuna objective for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 128),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 16),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 100),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 5.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 5.0),\n",
    "        \"scale_pos_weight\": 1.0,  # Balanced dataset\n",
    "    }\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dval = lgb.Dataset(X_val, label=y_val)\n",
    "    booster = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        valid_sets=[dval],\n",
    "        num_boost_round=200,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=20), lgb.log_evaluation(0)],\n",
    "    )\n",
    "    preds = booster.predict(X_val)\n",
    "    auc = roc_auc_score(y_val, preds)\n",
    "    return auc\n",
    "\n",
    "# 3. Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "# 4. Train final model with best parameters\n",
    "best_params = study.best_params\n",
    "best_params.update({\"objective\": \"binary\", \"metric\": \"auc\", \"verbosity\": -1})\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "dval = lgb.Dataset(X_val, label=y_val)\n",
    "booster = lgb.train(\n",
    "    best_params,\n",
    "    dtrain,\n",
    "    valid_sets=[dval],\n",
    "    num_boost_round=200,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=20), lgb.log_evaluation(20)],\n",
    ")\n",
    "\n",
    "# 5. Evaluate on validation set with multiple thresholds\n",
    "pred_probs = booster.predict(X_val)\n",
    "thresholds = [0.5, 0.4, 0.3]\n",
    "for threshold in thresholds:\n",
    "    preds = (pred_probs >= threshold).astype(int)\n",
    "    print(f\"\\n=== Results for threshold={threshold} ===\")\n",
    "    print(\"AUC:\", roc_auc_score(y_val, pred_probs))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, preds))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_val, preds))\n",
    "\n",
    "# 6. Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    \"Feature\": feature_cols,\n",
    "    \"Importance\": booster.feature_importance(importance_type=\"gain\"),\n",
    "})\n",
    "importance = importance.sort_values(\"Importance\", ascending=False)\n",
    "print(\"\\nFeature Importance:\\n\", importance)\n",
    "\n",
    "# 7. Wrap model in sklearn-compatible interface\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, booster, feature_names, le_user_agent, le_client_ip):\n",
    "        self.booster = booster\n",
    "        self.feature_names = feature_names\n",
    "        self.le_user_agent = le_user_agent\n",
    "        self.le_client_ip = le_client_ip\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Handle DataFrame input\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.copy()\n",
    "            if \"user_agent\" in X.columns:\n",
    "                X[\"user_agent\"] = self.le_user_agent.transform(X[\"user_agent\"])\n",
    "            if \"client_ip\" in X.columns:\n",
    "                X[\"client_ip\"] = self.le_client_ip.transform(X[\"client_ip\"])\n",
    "            X = X[self.feature_names].values.astype(np.float32)\n",
    "        else:\n",
    "            X = np.asarray(X, dtype=np.float32)\n",
    "        p1 = self.booster.predict(X)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.vstack([p0, p1]).T\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        proba = self.predict_proba(X)[:, 1]\n",
    "        return (proba >= threshold).astype(int)\n",
    "\n",
    "# 8. Save model\n",
    "clf = LGBMWrapper(booster, feature_cols, le_user_agent, le_client_ip)\n",
    "os.makedirs(\"app/models\", exist_ok=True)\n",
    "joblib.dump(clf, MODEL_PATH)\n",
    "print(f\"\\n✅ Saved model to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e825cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's auc: 1\n",
      "[40]\tvalid_0's auc: 1\n",
      "[60]\tvalid_0's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 1\n",
      "\n",
      "=== Results for threshold=0.5 ===\n",
      "AUC: 0.9999999175000001\n",
      "Confusion Matrix:\n",
      " [[19996     4]\n",
      " [    5 19995]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20000\n",
      "           1       1.00      1.00      1.00     20000\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "\n",
      "=== Results for threshold=0.4 ===\n",
      "AUC: 0.9999999175000001\n",
      "Confusion Matrix:\n",
      " [[19996     4]\n",
      " [    1 19999]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20000\n",
      "           1       1.00      1.00      1.00     20000\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "\n",
      "=== Results for threshold=0.3 ===\n",
      "AUC: 0.9999999175000001\n",
      "Confusion Matrix:\n",
      " [[19995     5]\n",
      " [    1 19999]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20000\n",
      "           1       1.00      1.00      1.00     20000\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                          Feature    Importance\n",
      "0                 time_to_submit  1.038912e+06\n",
      "1  failed_login_count_last_10min  2.267703e+03\n",
      "2                     user_agent  4.338271e+02\n",
      "\n",
      "✅ Saved model to app/models/slim_login_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script to train a slim LightGBM model on balanced_login_data.csv using the top 3 features\n",
    "(time_to_submit, failed_login_count_last_10min, user_agent). Saves the model as\n",
    "app/models/slim_login_classifier.pkl.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"balanced_login_data.csv\"\n",
    "MODEL_PATH = \"app/models/slim_login_classifier.pkl\"\n",
    "VALIDATION_SIZE = 0.1\n",
    "RANDOM_SEED = 42\n",
    "BEST_PARAMS = {\n",
    "    \"learning_rate\": 0.16296242250101053,\n",
    "    \"num_leaves\": 75,\n",
    "    \"max_depth\": 15,\n",
    "    \"feature_fraction\": 0.9199843192078083,\n",
    "    \"bagging_fraction\": 0.6271157784617101,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"min_data_in_leaf\": 34,\n",
    "    \"lambda_l1\": 0.0009722459428442853,\n",
    "    \"lambda_l2\": 4.9156352459893995,\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 1. Load and preprocess data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Encode categorical feature\n",
    "le_user_agent = LabelEncoder()\n",
    "df[\"user_agent\"] = le_user_agent.fit_transform(df[\"user_agent\"])\n",
    "\n",
    "# Select top 3 features\n",
    "feature_cols = [\n",
    "    \"time_to_submit\",\n",
    "    \"failed_login_count_last_10min\",\n",
    "    \"user_agent\",\n",
    "]\n",
    "X = df[feature_cols]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Split data (90% train, 10% validation, stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=VALIDATION_SIZE, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# 2. Train model with best parameters\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "dval = lgb.Dataset(X_val, label=y_val)\n",
    "booster = lgb.train(\n",
    "    BEST_PARAMS,\n",
    "    dtrain,\n",
    "    valid_sets=[dval],\n",
    "    num_boost_round=200,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=20), lgb.log_evaluation(20)],\n",
    ")\n",
    "\n",
    "# 3. Evaluate on validation set with multiple thresholds\n",
    "pred_probs = booster.predict(X_val)\n",
    "thresholds = [0.5, 0.4, 0.3]\n",
    "for threshold in thresholds:\n",
    "    preds = (pred_probs >= threshold).astype(int)\n",
    "    print(f\"\\n=== Results for threshold={threshold} ===\")\n",
    "    print(\"AUC:\", roc_auc_score(y_val, pred_probs))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, preds))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_val, preds))\n",
    "\n",
    "# 4. Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    \"Feature\": feature_cols,\n",
    "    \"Importance\": booster.feature_importance(importance_type=\"gain\"),\n",
    "})\n",
    "importance = importance.sort_values(\"Importance\", ascending=False)\n",
    "print(\"\\nFeature Importance:\\n\", importance)\n",
    "\n",
    "# 5. Wrap model in sklearn-compatible interface\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, booster, feature_names, le_user_agent):\n",
    "        self.booster = booster\n",
    "        self.feature_names = feature_names\n",
    "        self.le_user_agent = le_user_agent\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.copy()\n",
    "            if \"user_agent\" in X.columns:\n",
    "                X[\"user_agent\"] = self.le_user_agent.transform(X[\"user_agent\"])\n",
    "            X = X[self.feature_names].values.astype(np.float32)\n",
    "        else:\n",
    "            X = np.asarray(X, dtype=np.float32)\n",
    "        p1 = self.booster.predict(X)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.vstack([p0, p1]).T\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        proba = self.predict_proba(X)[:, 1]\n",
    "        return (proba >= threshold).astype(int)\n",
    "\n",
    "# 6. Save model\n",
    "clf = LGBMWrapper(booster, feature_cols, le_user_agent)\n",
    "os.makedirs(\"app/models\", exist_ok=True)\n",
    "joblib.dump(clf, MODEL_PATH)\n",
    "print(f\"\\n✅ Saved model to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899fb984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ensemble Results ===\n",
      "AUC: 1.0\n",
      "Confusion Matrix:\n",
      " [[5000    0]\n",
      " [   0 5000]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      5000\n",
      "         1.0       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "\n",
      "✅ Saved ensemble model to app/models/ensemble_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script to create an ensemble classifier combining the slim login-behavior model\n",
    "and network-flow model. Generates a synthetic test dataset, evaluates the ensemble\n",
    "with adjustable threshold and logic, and saves it as app/models/ensemble_classifier.pkl.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Configuration\n",
    "LOGIN_MODEL_PATH = \"app/models/slim_login_classifier.pkl\"\n",
    "NETWORK_MODEL_PATH = \"D:\\\\Canada\\\\Subjects\\\\Semester -2\\\\AIDI-2005-02 CAPSTONE TERM ll\\\\Bot_detector\\\\notebooks\\\\final_lightgbm_tuned.txt\"\n",
    "ENSEMBLE_MODEL_PATH = \"app/models/ensemble_classifier.pkl\"\n",
    "TEST_SIZE = 10000\n",
    "RANDOM_SEED = 42\n",
    "THRESHOLD = 0.5  # Increased to 0.5 for better balance\n",
    "USE_MAX_PROB = False  # Set to True for max probability rule instead of averaging\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 1. Generate synthetic test dataset\n",
    "def generate_synthetic_test_data(n_samples=TEST_SIZE):\n",
    "    n_benign = n_samples // 2\n",
    "    n_attack = n_samples - n_benign\n",
    "    data = {\n",
    "        # Login-behavior features (from balanced_login_data.csv distributions)\n",
    "        \"time_to_submit\": np.concatenate([\n",
    "            np.random.uniform(1.5, 12.0, n_benign),  # Benign: 1.5-12s\n",
    "            np.random.uniform(0.02, 0.6, n_attack)   # Attack: 0.02-0.6s\n",
    "        ]),\n",
    "        \"failed_login_count_last_10min\": np.concatenate([\n",
    "            np.random.randint(0, 3, n_benign),       # Benign: 0-2\n",
    "            np.random.randint(3, 16, n_attack)       # Attack: 3-15\n",
    "        ]),\n",
    "        \"user_agent\": np.concatenate([\n",
    "            np.random.choice(\n",
    "                [\"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)\", \"Chrome/90.0\"],\n",
    "                n_benign, p=[0.4, 0.3, 0.3]\n",
    "            ),\n",
    "            np.random.choice(\n",
    "                [\"curl/8.5.0\", \"python-requests/2.28.1\", \"BotAgent\"],\n",
    "                n_attack, p=[0.5, 0.3, 0.2]\n",
    "            )\n",
    "        ]),\n",
    "        # Placeholder network-flow features (78 features, simplified distributions)\n",
    "        **{\n",
    "            f\"flow_feature_{i}\": np.random.uniform(0, 100, n_samples) for i in range(78)\n",
    "        },\n",
    "        \"label\": np.concatenate([np.zeros(n_benign), np.ones(n_attack)])\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# 2. Load models\n",
    "login_model = joblib.load(LOGIN_MODEL_PATH)\n",
    "network_model = lgb.Booster(model_file=NETWORK_MODEL_PATH)\n",
    "\n",
    "# 3. Ensemble classifier\n",
    "class EnsembleClassifier:\n",
    "    def __init__(self, login_model, network_model, login_features, network_features, threshold=0.3):\n",
    "        self.login_model = login_model\n",
    "        self.network_model = network_model\n",
    "        self.login_features = login_features\n",
    "        self.network_features = network_features\n",
    "        self.threshold = threshold\n",
    "        self.le_user_agent = LabelEncoder()  # Initialize new LabelEncoder\n",
    "\n",
    "    def fit_encoders(self, X):\n",
    "        # Fit LabelEncoder on user_agent values from the input data\n",
    "        self.le_user_agent.fit(X[\"user_agent\"])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.copy()\n",
    "            if \"user_agent\" in X.columns:\n",
    "                X[\"user_agent\"] = self.le_user_agent.transform(X[\"user_agent\"])\n",
    "            X_login = X[self.login_features].values.astype(np.float32)\n",
    "            X_network = X[self.network_features].values.astype(np.float32)\n",
    "        else:\n",
    "            X_login = X[:, :len(self.login_features)].astype(np.float32)\n",
    "            X_network = X[:, len(self.login_features):].astype(np.float32)\n",
    "        login_probs = self.login_model.predict_proba(X_login)[:, 1]\n",
    "        network_probs = self.network_model.predict(X_network)\n",
    "        if USE_MAX_PROB:\n",
    "            ensemble_probs = np.maximum(login_probs, network_probs)\n",
    "        else:\n",
    "            ensemble_probs = (login_probs + network_probs) / 2\n",
    "        return np.vstack([1 - ensemble_probs, ensemble_probs]).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)[:, 1]\n",
    "        return (proba >= self.threshold).astype(int)\n",
    "\n",
    "# 4. Generate and preprocess test data\n",
    "test_df = generate_synthetic_test_data()\n",
    "login_features = [\"time_to_submit\", \"failed_login_count_last_10min\", \"user_agent\"]\n",
    "network_features = [f\"flow_feature_{i}\" for i in range(78)]\n",
    "X_test = test_df[login_features + network_features]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "# 5. Create and evaluate ensemble\n",
    "ensemble = EnsembleClassifier(login_model, network_model, login_features, network_features, THRESHOLD)\n",
    "ensemble.fit_encoders(X_test)  # Fit LabelEncoder on test data\n",
    "pred_probs = ensemble.predict_proba(X_test)[:, 1]\n",
    "preds = ensemble.predict(X_test)\n",
    "\n",
    "# 6. Print evaluation metrics\n",
    "print(\"\\n=== Ensemble Results ===\")\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_probs))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n",
    "\n",
    "# 7. Save ensemble model\n",
    "os.makedirs(\"app/models\", exist_ok=True)\n",
    "joblib.dump(ensemble, ENSEMBLE_MODEL_PATH)\n",
    "print(f\"\\n✅ Saved ensemble model to {ENSEMBLE_MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
